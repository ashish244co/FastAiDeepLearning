{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":135,"outputs":[{"output_type":"stream","text":"/kaggle/input/tweet-sentiment-extraction/sample_submission.csv\n/kaggle/input/tweet-sentiment-extraction/test.csv\n/kaggle/input/tweet-sentiment-extraction/train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/input/tweet-sentiment-extraction/')","execution_count":136,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=pd.read_csv('train.csv')","execution_count":137,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=dataset.drop(['textID','selected_text'],axis=1)","execution_count":138,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['text'][:10]","execution_count":139,"outputs":[{"output_type":"execute_result","execution_count":139,"data":{"text/plain":"0                                                             I`d have responded, if I were going\n1                                                   Sooo SAD I will miss you here in San Diego!!!\n2                                                                       my boss is bullying me...\n3                                                                  what interview! leave me alone\n4                      Sons of ****, why couldn`t they put them on the releases we already bought\n5    http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth\n6                                2am feedings for the baby are fun when he is all smiles and coos\n7                                                                                      Soooo high\n8                                                                                     Both of you\n9                            Journey!? Wow... u just became cooler.  hehe... (is that possible!?)\nName: text, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"testset=pd.read_csv('test.csv')\ntestset=testset.drop(['textID'],axis=1)","execution_count":140,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testset.head()","execution_count":141,"outputs":[{"output_type":"execute_result","execution_count":141,"data":{"text/plain":"                                                                                                      text  \\\n0                                                        Last session of the day  http://twitpic.com/67ezh   \n1   Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).   \n2                           Recession hit Veronique Branquinho, she has to quit her company, such a shame!   \n3                                                                                              happy bday!   \n4                                                                   http://twitpic.com/4w75p - I like it!!   \n\n  sentiment  \n0   neutral  \n1  positive  \n2  negative  \n3  positive  \n4  positive  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Last session of the day  http://twitpic.com/67ezh</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Recession hit Veronique Branquinho, she has to quit her company, such a shame!</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>happy bday!</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://twitpic.com/4w75p - I like it!!</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport string","execution_count":142,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EMOTICONS = {\n    u\":‑\\)\":\"Happy face or smiley\",\n    u\":\\)\":\"Happy face or smiley\",\n    u\":-\\]\":\"Happy face or smiley\",\n    u\":\\]\":\"Happy face or smiley\",\n    u\":-3\":\"Happy face smiley\",\n    u\":3\":\"Happy face smiley\",\n    u\":->\":\"Happy face smiley\",\n    u\":>\":\"Happy face smiley\",\n    u\"8-\\)\":\"Happy face smiley\",\n    u\":o\\)\":\"Happy face smiley\",\n    u\":-\\}\":\"Happy face smiley\",\n    u\":\\}\":\"Happy face smiley\",\n    u\":-\\)\":\"Happy face smiley\",\n    u\":c\\)\":\"Happy face smiley\",\n    u\":\\^\\)\":\"Happy face smiley\",\n    u\"=\\]\":\"Happy face smiley\",\n    u\"=\\)\":\"Happy face smiley\",\n    u\":‑D\":\"Laughing, big grin or laugh with glasses\",\n    u\":D\":\"Laughing, big grin or laugh with glasses\",\n    u\"8‑D\":\"Laughing, big grin or laugh with glasses\",\n    u\"8D\":\"Laughing, big grin or laugh with glasses\",\n    u\"X‑D\":\"Laughing, big grin or laugh with glasses\",\n    u\"XD\":\"Laughing, big grin or laugh with glasses\",\n    u\"=D\":\"Laughing, big grin or laugh with glasses\",\n    u\"=3\":\"Laughing, big grin or laugh with glasses\",\n    u\"B\\^D\":\"Laughing, big grin or laugh with glasses\",\n    u\":-\\)\\)\":\"Very happy\",\n    u\":‑\\(\":\"Frown, sad, andry or pouting\",\n    u\":-\\(\":\"Frown, sad, andry or pouting\",\n    u\":\\(\":\"Frown, sad, andry or pouting\",\n    u\":‑c\":\"Frown, sad, andry or pouting\",\n    u\":c\":\"Frown, sad, andry or pouting\",\n    u\":‑<\":\"Frown, sad, andry or pouting\",\n    u\":<\":\"Frown, sad, andry or pouting\",\n    u\":‑\\[\":\"Frown, sad, andry or pouting\",\n    u\":\\[\":\"Frown, sad, andry or pouting\",\n    u\":-\\|\\|\":\"Frown, sad, andry or pouting\",\n    u\">:\\[\":\"Frown, sad, andry or pouting\",\n    u\":\\{\":\"Frown, sad, andry or pouting\",\n    u\":@\":\"Frown, sad, andry or pouting\",\n    u\">:\\(\":\"Frown, sad, andry or pouting\",\n    u\":'‑\\(\":\"Crying\",\n    u\":'\\(\":\"Crying\",\n    u\":'‑\\)\":\"Tears of happiness\",\n    u\":'\\)\":\"Tears of happiness\",\n    u\"D‑':\":\"Horror\",\n    u\"D:<\":\"Disgust\",\n    u\"D:\":\"Sadness\",\n    u\"D8\":\"Great dismay\",\n    u\"D;\":\"Great dismay\",\n    u\"D=\":\"Great dismay\",\n    u\"DX\":\"Great dismay\",\n    u\":‑O\":\"Surprise\",\n    u\":O\":\"Surprise\",\n    u\":‑o\":\"Surprise\",\n    u\":o\":\"Surprise\",\n    u\":-0\":\"Shock\",\n    u\"8‑0\":\"Yawn\",\n    u\">:O\":\"Yawn\",\n    u\":-\\*\":\"Kiss\",\n    u\":\\*\":\"Kiss\",\n    u\":X\":\"Kiss\",\n    u\";‑\\)\":\"Wink or smirk\",\n    u\";\\)\":\"Wink or smirk\",\n    u\"\\*-\\)\":\"Wink or smirk\",\n    u\"\\*\\)\":\"Wink or smirk\",\n    u\";‑\\]\":\"Wink or smirk\",\n    u\";\\]\":\"Wink or smirk\",\n    u\";\\^\\)\":\"Wink or smirk\",\n    u\":‑,\":\"Wink or smirk\",\n    u\";D\":\"Wink or smirk\",\n    u\":‑P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\":P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\"X‑P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\"XP\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\":‑Þ\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\":Þ\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\":b\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\"d:\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\"=p\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\">:P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\":‑/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":-[.]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\">:[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\">:/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\"=/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\"=[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":L\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\"=L\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":S\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":‑\\|\":\"Straight face\",\n    u\":\\|\":\"Straight face\",\n    u\":$\":\"Embarrassed or blushing\",\n    u\":‑x\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\":x\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\":‑#\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\":#\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\":‑&\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\":&\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\"O:‑\\)\":\"Angel, saint or innocent\",\n    u\"O:\\)\":\"Angel, saint or innocent\",\n    u\"0:‑3\":\"Angel, saint or innocent\",\n    u\"0:3\":\"Angel, saint or innocent\",\n    u\"0:‑\\)\":\"Angel, saint or innocent\",\n    u\"0:\\)\":\"Angel, saint or innocent\",\n    u\":‑b\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\"0;\\^\\)\":\"Angel, saint or innocent\",\n    u\">:‑\\)\":\"Evil or devilish\",\n    u\">:\\)\":\"Evil or devilish\",\n    u\"\\}:‑\\)\":\"Evil or devilish\",\n    u\"\\}:\\)\":\"Evil or devilish\",\n    u\"3:‑\\)\":\"Evil or devilish\",\n    u\"3:\\)\":\"Evil or devilish\",\n    u\">;\\)\":\"Evil or devilish\",\n    u\"\\|;‑\\)\":\"Cool\",\n    u\"\\|‑O\":\"Bored\",\n    u\":‑J\":\"Tongue-in-cheek\",\n    u\"#‑\\)\":\"Party all night\",\n    u\"%‑\\)\":\"Drunk or confused\",\n    u\"%\\)\":\"Drunk or confused\",\n    u\":-###..\":\"Being sick\",\n    u\":###..\":\"Being sick\",\n    u\"<:‑\\|\":\"Dump\",\n    u\"\\(>_<\\)\":\"Troubled\",\n    u\"\\(>_<\\)>\":\"Troubled\",\n    u\"\\(';'\\)\":\"Baby\",\n    u\"\\(\\^\\^>``\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n    u\"\\(\\^_\\^;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n    u\"\\(-_-;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n    u\"\\(~_~;\\) \\(・\\.・;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n    u\"\\(-_-\\)zzz\":\"Sleeping\",\n    u\"\\(\\^_-\\)\":\"Wink\",\n    u\"\\(\\(\\+_\\+\\)\\)\":\"Confused\",\n    u\"\\(\\+o\\+\\)\":\"Confused\",\n    u\"\\(o\\|o\\)\":\"Ultraman\",\n    u\"\\^_\\^\":\"Joyful\",\n    u\"\\(\\^_\\^\\)/\":\"Joyful\",\n    u\"\\(\\^O\\^\\)／\":\"Joyful\",\n    u\"\\(\\^o\\^\\)／\":\"Joyful\",\n    u\"\\(__\\)\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"_\\(\\._\\.\\)_\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"<\\(_ _\\)>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"<m\\(__\\)m>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"m\\(__\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"m\\(_ _\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"\\('_'\\)\":\"Sad or Crying\",\n    u\"\\(/_;\\)\":\"Sad or Crying\",\n    u\"\\(T_T\\) \\(;_;\\)\":\"Sad or Crying\",\n    u\"\\(;_;\":\"Sad of Crying\",\n    u\"\\(;_:\\)\":\"Sad or Crying\",\n    u\"\\(;O;\\)\":\"Sad or Crying\",\n    u\"\\(:_;\\)\":\"Sad or Crying\",\n    u\"\\(ToT\\)\":\"Sad or Crying\",\n    u\";_;\":\"Sad or Crying\",\n    u\";-;\":\"Sad or Crying\",\n    u\";n;\":\"Sad or Crying\",\n    u\";;\":\"Sad or Crying\",\n    u\"Q\\.Q\":\"Sad or Crying\",\n    u\"T\\.T\":\"Sad or Crying\",\n    u\"QQ\":\"Sad or Crying\",\n    u\"Q_Q\":\"Sad or Crying\",\n    u\"\\(-\\.-\\)\":\"Shame\",\n    u\"\\(-_-\\)\":\"Shame\",\n    u\"\\(一一\\)\":\"Shame\",\n    u\"\\(；一_一\\)\":\"Shame\",\n    u\"\\(=_=\\)\":\"Tired\",\n    u\"\\(=\\^\\·\\^=\\)\":\"cat\",\n    u\"\\(=\\^\\·\\·\\^=\\)\":\"cat\",\n    u\"=_\\^=\t\":\"cat\",\n    u\"\\(\\.\\.\\)\":\"Looking down\",\n    u\"\\(\\._\\.\\)\":\"Looking down\",\n    u\"\\^m\\^\":\"Giggling with hand covering mouth\",\n    u\"\\(\\・\\・?\":\"Confusion\",\n    u\"\\(?_?\\)\":\"Confusion\",\n    u\">\\^_\\^<\":\"Normal Laugh\",\n    u\"<\\^!\\^>\":\"Normal Laugh\",\n    u\"\\^/\\^\":\"Normal Laugh\",\n    u\"\\（\\*\\^_\\^\\*）\" :\"Normal Laugh\",\n    u\"\\(\\^<\\^\\) \\(\\^\\.\\^\\)\":\"Normal Laugh\",\n    u\"\\(^\\^\\)\":\"Normal Laugh\",\n    u\"\\(\\^\\.\\^\\)\":\"Normal Laugh\",\n    u\"\\(\\^_\\^\\.\\)\":\"Normal Laugh\",\n    u\"\\(\\^_\\^\\)\":\"Normal Laugh\",\n    u\"\\(\\^\\^\\)\":\"Normal Laugh\",\n    u\"\\(\\^J\\^\\)\":\"Normal Laugh\",\n    u\"\\(\\*\\^\\.\\^\\*\\)\":\"Normal Laugh\",\n    u\"\\(\\^—\\^\\）\":\"Normal Laugh\",\n    u\"\\(#\\^\\.\\^#\\)\":\"Normal Laugh\",\n    u\"\\（\\^—\\^\\）\":\"Waving\",\n    u\"\\(;_;\\)/~~~\":\"Waving\",\n    u\"\\(\\^\\.\\^\\)/~~~\":\"Waving\",\n    u\"\\(-_-\\)/~~~ \\($\\·\\·\\)/~~~\":\"Waving\",\n    u\"\\(T_T\\)/~~~\":\"Waving\",\n    u\"\\(ToT\\)/~~~\":\"Waving\",\n    u\"\\(\\*\\^0\\^\\*\\)\":\"Excited\",\n    u\"\\(\\*_\\*\\)\":\"Amazed\",\n    u\"\\(\\*_\\*;\":\"Amazed\",\n    u\"\\(\\+_\\+\\) \\(@_@\\)\":\"Amazed\",\n    u\"\\(\\*\\^\\^\\)v\":\"Laughing,Cheerful\",\n    u\"\\(\\^_\\^\\)v\":\"Laughing,Cheerful\",\n    u\"\\(\\(d[-_-]b\\)\\)\":\"Headphones,Listening to music\",\n    u'\\(-\"-\\)':\"Worried\",\n    u\"\\(ーー;\\)\":\"Worried\",\n    u\"\\(\\^0_0\\^\\)\":\"Eyeglasses\",\n    u\"\\(\\＾ｖ\\＾\\)\":\"Happy\",\n    u\"\\(\\＾ｕ\\＾\\)\":\"Happy\",\n    u\"\\(\\^\\)o\\(\\^\\)\":\"Happy\",\n    u\"\\(\\^O\\^\\)\":\"Happy\",\n    u\"\\(\\^o\\^\\)\":\"Happy\",\n    u\"\\)\\^o\\^\\(\":\"Happy\",\n    u\":O o_O\":\"Surprised\",\n    u\"o_0\":\"Surprised\",\n    u\"o\\.O\":\"Surpised\",\n    u\"\\(o\\.o\\)\":\"Surprised\",\n    u\"oO\":\"Surprised\",\n    u\"\\(\\*￣m￣\\)\":\"Dissatisfied\",\n    u\"\\(‘A`\\)\":\"Snubbed or Deflated\"\n}\nfrom nltk.corpus import stopwords\n","execution_count":143,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk","execution_count":127,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\ndef decontracted(phrase):\n    # specific\n    phrase=phrase.lower()\n    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\`t\", \" not\", phrase)\n    phrase = re.sub(r\"\\`re\", \" are\", phrase)\n    phrase = re.sub(r\"\\`s\", \" is\", phrase)\n    phrase = re.sub(r\"\\`d\", \" would\", phrase)\n    phrase = re.sub(r\"\\`ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\`t\", \" not\", phrase)\n    phrase = re.sub(r\"\\`ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\`m\", \" am\", phrase)\n    \n    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n        \n    return phrase","execution_count":146,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['text'][100]","execution_count":147,"outputs":[{"output_type":"execute_result","execution_count":147,"data":{"text/plain":"'4am. And Im on the beach. Pretty'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    text = re.sub('\\[.*?\\]', '', text)\n    text=re.sub(r'http\\S+', '', text)   \n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    text = re.sub(r'[^a-zA-Z ]', '', text)\n    return text\n\nSTOPWORDS = set(stopwords.words('english'))\ndef remove_stopwords(text):\n    \"\"\"custom function to remove the stopwords\"\"\"\n    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\nfrom nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\ndef lemmatize_words(text):\n    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\nwordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n\ndef lemmatize_words(text):\n    pos_tagged_text = nltk.pos_tag(text.split())\n    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n\ndef remove_emoji(string):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', string)\n\ndef remove_emoticons(text):\n    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in EMOTICONS) + u')')\n    return emoticon_pattern.sub(r'', text)\n\nchat_words_str = \"\"\"\nAFAIK=As Far As I Know\nAFK=Away From Keyboard\nASAP=As Soon As Possible\nATK=At The Keyboard\nATM=At The Moment\nA3=Anytime, Anywhere, Anyplace\nBAK=Back At Keyboard\nBBL=Be Back Later\nBBS=Be Back Soon\nBFN=Bye For Now\nB4N=Bye For Now\nBRB=Be Right Back\nBRT=Be Right There\nBTW=By The Way\nB4=Before\nB4N=Bye For Now\nCU=See You\nCUL8R=See You Later\nCYA=See You\nFAQ=Frequently Asked Questions\nFC=Fingers Crossed\nFWIW=For What It's Worth\nFYI=For Your Information\nGAL=Get A Life\nGG=Good Game\nGN=Good Night\nGMTA=Great Minds Think Alike\nGR8=Great!\nG9=Genius\nIC=I See\nICQ=I Seek you (also a chat program)\nILU=ILU: I Love You\nIMHO=In My Honest/Humble Opinion\nIMO=In My Opinion\nIOW=In Other Words\nIRL=In Real Life\nKISS=Keep It Simple, Stupid\nLDR=Long Distance Relationship\nLMAO=Laugh My A.. Off\nLOL=Laughing Out Loud\nLTNS=Long Time No See\nL8R=Later\nMTE=My Thoughts Exactly\nM8=Mate\nNRN=No Reply Necessary\nOIC=Oh I See\nPITA=Pain In The A..\nPRT=Party\nPRW=Parents Are Watching\nROFL=Rolling On The Floor Laughing\nROFLOL=Rolling On The Floor Laughing Out Loud\nROTFLMAO=Rolling On The Floor Laughing My A.. Off\nSK8=Skate\nSTATS=Your sex and age\nASL=Age, Sex, Location\nTHX=Thank You\nTTFN=Ta-Ta For Now!\nTTYL=Talk To You Later\nU=You\nU2=You Too\nU4E=Yours For Ever\nWB=Welcome Back\nWTF=What The F...\nWTG=Way To Go!\nWUF=Where Are You From?\nW8=Wait...\n7K=Sick:-D Laugher\n\"\"\"\n\nchat_words_map_dict = {}\nchat_words_list = []\nfor line in chat_words_str.split(\"\\n\"):\n    if line != \"\":\n        cw = line.split(\"=\")[0]\n        cw_expanded = line.split(\"=\")[1]\n        chat_words_list.append(cw)\n        chat_words_map_dict[cw] = cw_expanded\nchat_words_list = set(chat_words_list)\n\ndef chat_words_conversion(text):\n    new_text = []\n    for w in text.split():\n        if w.upper() in chat_words_list:\n            new_text.append(chat_words_map_dict[w.upper()])\n        else:\n            new_text.append(w)\n    return \" \".join(new_text)","execution_count":148,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['text']=dataset['text'].str.lower()\ndataset['text']=dataset['text'].apply(lambda x :remove_emoji(str(x)))\ndataset['text']=dataset['text'].str.lower()\ndataset['text']=dataset['text'].apply(lambda x :remove_emoticons(x))\ndataset['text']=dataset['text'].str.lower()\ndataset['text']=dataset['text'].apply(lambda x :chat_words_conversion(x))\ndataset['text']=dataset['text'].str.lower()\ndataset['text']=dataset['text'].apply(lambda x :decontracted(str(x)))\ndataset['text']=dataset['text'].str.lower()\ndataset['text']=dataset['text'].apply(lambda x :clean_text(str(x)))\ndataset['text']=dataset['text'].str.lower()\ndataset['text']=dataset['text'].apply(lambda x :lemmatize_words(x))\n\ndataset['text']=dataset['text'].str.lower()","execution_count":149,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testset['text']=testset['text'].str.lower()\ntestset['text']=testset['text'].apply(lambda x :remove_emoji(str(x)))\ndataset['text']=dataset['text'].str.lower()\ntestset['text']=testset['text'].apply(lambda x :remove_emoticons(x))\ndataset['text']=dataset['text'].str.lower()\ntestset['text']=testset['text'].apply(lambda x :chat_words_conversion(x))\ndataset['text']=dataset['text'].str.lower()\ntestset['text']=testset['text'].apply(lambda x :decontracted(str(x)))\ndataset['text']=dataset['text'].str.lower()\ntestset['text']=testset['text'].apply(lambda x :clean_text(str(x)))\ndataset['text']=dataset['text'].str.lower()\ntestset['text']=testset['text'].apply(lambda x :lemmatize_words(x))\ntestset['text']=testset['text'].str.lower()","execution_count":150,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total=pd.concat([dataset,testset])","execution_count":151,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total['text'][:10]","execution_count":152,"outputs":[{"output_type":"execute_result","execution_count":152,"data":{"text/plain":"0                                     i would have respond if i be go\n1                          sooo sad i will miss you here in san diego\n2                                                  my bos be bully me\n3                                       what interview leave me alone\n4    son of why could not they put them on the release we already buy\n5              some shameless plug for the best ranger forum on earth\n6            feeding for the baby be fun when he be all smile and coo\n7                                                          soooo high\n8                                                         both of you\n9              journey wow you just become cool hehe be that possible\nName: text, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install fastai2","execution_count":115,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: fastai2 in /opt/conda/lib/python3.7/site-packages (0.0.17)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from fastai2) (1.4.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from fastai2) (0.22.2.post1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from fastai2) (5.3.1)\nRequirement already satisfied: torch>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from fastai2) (1.5.0)\nRequirement already satisfied: fastcore in /opt/conda/lib/python3.7/site-packages (from fastai2) (0.1.17)\nRequirement already satisfied: torchvision>=0.5 in /opt/conda/lib/python3.7/site-packages (from fastai2) (0.6.0a0+82fd1c8)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from fastai2) (5.4.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from fastai2) (3.2.1)\nRequirement already satisfied: spacy in /opt/conda/lib/python3.7/site-packages (from fastai2) (2.2.3)\nRequirement already satisfied: fastprogress>=0.1.22 in /opt/conda/lib/python3.7/site-packages (from fastai2) (0.2.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fastai2) (2.23.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fastai2) (1.0.3)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from scipy->fastai2) (1.18.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->fastai2) (0.14.1)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.3.0->fastai2) (0.18.2)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai2) (2.4.7)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai2) (2.8.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai2) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai2) (1.2.0)\nRequirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy->fastai2) (0.4.1)\nRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy->fastai2) (0.6.0)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy->fastai2) (3.0.2)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy->fastai2) (2.0.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy->fastai2) (46.1.3.post20200325)\nRequirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy->fastai2) (0.9.6)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy->fastai2) (1.0.2)\nRequirement already satisfied: srsly<1.1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from spacy->fastai2) (1.0.2)\nRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy->fastai2) (1.0.0)\nRequirement already satisfied: thinc<7.4.0,>=7.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy->fastai2) (7.3.1)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fastai2) (1.24.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fastai2) (2020.4.5.1)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fastai2) (2.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->fastai2) (3.0.4)\nRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->fastai2) (2019.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib->fastai2) (1.14.0)\nRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2) (1.6.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.10.0 in /opt/conda/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy->fastai2) (4.45.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2) (3.1.0)\n\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai2.text.all import *","execution_count":153,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dls = TextDataLoaders.from_df(total, text_col='text', is_lm=True, bs=128, seq_len=80)\ndls.show_batch(max_n=3)","execution_count":154,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>xxbos one load of wash put away and another load on amaze how the house do not look any good for all my effort xxbos that be awesome ca not believe they have the poster up already i have not see one over here yet xxbos i know right xxunk girl it show why they should not put young people in competition like this though xxbos sugar oh no i be always here xxbos no luck in goin to forum</td>\n      <td>one load of wash put away and another load on amaze how the house do not look any good for all my effort xxbos that be awesome ca not believe they have the poster up already i have not see one over here yet xxbos i know right xxunk girl it show why they should not put young people in competition like this though xxbos sugar oh no i be always here xxbos no luck in goin to forum i</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>xxbos walk past the school i go to junior high in a it be be tear down xxbos feel good still cough not move on yet it impossible xxbos look like i get a xxunk macbook xxbos oh no it ok they be come on just now x xxbos ca nt find my shoe hope it as bad a it ll get i m happy xxbos good to have a boyfriend like you xxbos hi x your website soo cool</td>\n      <td>walk past the school i go to junior high in a it be be tear down xxbos feel good still cough not move on yet it impossible xxbos look like i get a xxunk macbook xxbos oh no it ok they be come on just now x xxbos ca nt find my shoe hope it as bad a it ll get i m happy xxbos good to have a boyfriend like you xxbos hi x your website soo cool i</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>someone xxunk knock at my door xxbos btw xxunk be try to beat his flight control score as well maybe you should follow each other xxbos nope neither of our lady be on today xxbos xxunk grace timberlake have a ring to it xxbos thanks for a great night dear perfectly complete my weekend xxbos it awsome when you know that you know that you know xxbos a xxrep 4 w xxunk when ppl make fun of someone laugh their</td>\n      <td>xxunk knock at my door xxbos btw xxunk be try to beat his flight control score as well maybe you should follow each other xxbos nope neither of our lady be on today xxbos xxunk grace timberlake have a ring to it xxbos thanks for a great night dear perfectly complete my weekend xxbos it awsome when you know that you know that you know xxbos a xxrep 4 w xxunk when ppl make fun of someone laugh their ass</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = language_model_learner(dls, AWD_LSTM, drop_mult=0.3, metrics=[accuracy],model_dir=\"/tmp/model/\")","execution_count":155,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10, 2e-3)","execution_count":156,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>6.617160</td>\n      <td>6.224939</td>\n      <td>0.089536</td>\n      <td>00:33</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>6.215685</td>\n      <td>5.506111</td>\n      <td>0.123227</td>\n      <td>00:33</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>5.760194</td>\n      <td>5.099595</td>\n      <td>0.153006</td>\n      <td>00:32</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>5.427315</td>\n      <td>4.947785</td>\n      <td>0.172554</td>\n      <td>00:33</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5.211040</td>\n      <td>4.875422</td>\n      <td>0.183793</td>\n      <td>00:32</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>5.069867</td>\n      <td>4.834860</td>\n      <td>0.188726</td>\n      <td>00:33</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>4.975963</td>\n      <td>4.812214</td>\n      <td>0.192274</td>\n      <td>00:32</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>4.914463</td>\n      <td>4.800784</td>\n      <td>0.193563</td>\n      <td>00:32</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>4.879329</td>\n      <td>4.796320</td>\n      <td>0.194156</td>\n      <td>00:32</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>4.856500</td>\n      <td>4.795552</td>\n      <td>0.194542</td>\n      <td>00:32</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(10, 2e-4)","execution_count":157,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>4.824502</td>\n      <td>4.771616</td>\n      <td>0.199249</td>\n      <td>00:35</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>4.789272</td>\n      <td>4.723950</td>\n      <td>0.206554</td>\n      <td>00:34</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4.748705</td>\n      <td>4.687513</td>\n      <td>0.211035</td>\n      <td>00:34</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4.710445</td>\n      <td>4.663615</td>\n      <td>0.214735</td>\n      <td>00:34</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4.680483</td>\n      <td>4.651900</td>\n      <td>0.216053</td>\n      <td>00:34</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>4.650959</td>\n      <td>4.637079</td>\n      <td>0.217396</td>\n      <td>00:34</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>4.630020</td>\n      <td>4.630718</td>\n      <td>0.217852</td>\n      <td>00:33</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>4.617136</td>\n      <td>4.627446</td>\n      <td>0.218587</td>\n      <td>00:34</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>4.609262</td>\n      <td>4.626242</td>\n      <td>0.218294</td>\n      <td>00:34</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>4.599982</td>\n      <td>4.625946</td>\n      <td>0.218464</td>\n      <td>00:34</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save_encoder('finetuned')","execution_count":158,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEXT = \"I love\"\nN_WORDS = 40\nN_SENTENCES = 2\npreds = [learn.predict(TEXT, N_WORDS, temperature=0.75) \n         for _ in range(N_SENTENCES)]","execution_count":159,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\n\".join(preds))","execution_count":160,"outputs":[{"output_type":"stream","text":"i love the item up on my head how be the a go to be me i wish i actually live in bed that be what i be come to say say you should have a slight drink off the\ni love you finally back to bed be at the moment of my birthday i have see the new weather there x just go to the gym and see the cat make me feel like and your farm be go away\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dls_clas = TextDataLoaders.from_df(df=total,train_df=dataset,valid_df=testset, text_col='text', is_lm=False, bs=128, seq_len=80)","execution_count":169,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dls_clas.show_batch(max_n=3)","execution_count":170,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>xxbos xxrep 3 a xxrep 3 w i m s xxrep 8 o tire today i do nt feel good i do nt wanna go to work wah but yeah i m goin to work in a few min til closing</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>xxbos u xxrep 4 m i have no idea what i m do but my friend be piss off at me now and i do nt know why she hat me so much i need help britney plz</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>xxbos i feel like an mm xxunk xxrep 3 m but i wo not get one coz i need to look good for when i go to the state week go xxrep 5 a xxrep 4 h</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, metrics=accuracy, model_dir=\"/tmp/model/\")","execution_count":171,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = learn.load_encoder('finetuned')","execution_count":172,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5, 2e-2)","execution_count":173,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.017824</td>\n      <td>0.869887</td>\n      <td>0.601806</td>\n      <td>00:36</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.988789</td>\n      <td>0.834555</td>\n      <td>0.625020</td>\n      <td>00:37</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.995574</td>\n      <td>0.820147</td>\n      <td>0.628083</td>\n      <td>00:37</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.970913</td>\n      <td>0.810596</td>\n      <td>0.632758</td>\n      <td>00:37</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.946728</td>\n      <td>0.802661</td>\n      <td>0.637595</td>\n      <td>00:38</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.freeze_to(-2)\nlearn.fit_one_cycle(5, slice(1e-2/(2.6**4),1e-2))","execution_count":174,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.877982</td>\n      <td>0.764780</td>\n      <td>0.651459</td>\n      <td>00:38</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.778768</td>\n      <td>0.710240</td>\n      <td>0.689989</td>\n      <td>00:37</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.721788</td>\n      <td>0.680249</td>\n      <td>0.702886</td>\n      <td>00:38</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.693434</td>\n      <td>0.658605</td>\n      <td>0.715460</td>\n      <td>00:38</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.672286</td>\n      <td>0.659053</td>\n      <td>0.717556</td>\n      <td>00:37</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.freeze_to(-4)\nlearn.fit_one_cycle(5, slice(5e-3/(2.6**4),5e-3))","execution_count":175,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.645192</td>\n      <td>0.654990</td>\n      <td>0.726423</td>\n      <td>00:38</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.621503</td>\n      <td>0.632551</td>\n      <td>0.737546</td>\n      <td>00:39</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.563069</td>\n      <td>0.647366</td>\n      <td>0.731904</td>\n      <td>00:39</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.496103</td>\n      <td>0.643478</td>\n      <td>0.740932</td>\n      <td>00:39</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.467811</td>\n      <td>0.651598</td>\n      <td>0.739481</td>\n      <td>00:40</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(5, slice(1e-3/(2.6**4),1e-3))","execution_count":176,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.464427</td>\n      <td>0.649668</td>\n      <td>0.741254</td>\n      <td>00:40</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.453892</td>\n      <td>0.673293</td>\n      <td>0.732710</td>\n      <td>00:39</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.440577</td>\n      <td>0.674354</td>\n      <td>0.737869</td>\n      <td>00:40</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.422052</td>\n      <td>0.690133</td>\n      <td>0.737546</td>\n      <td>00:40</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.419372</td>\n      <td>0.681971</td>\n      <td>0.737546</td>\n      <td>00:38</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pwd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('model1')","execution_count":177,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}